{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model for crash prediction\n",
    "### Developed by: bpben\n",
    "#### Details steps of data processing, feature engineering and model tuning/testing for crash and road data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "from glob import glob\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpers for tuning/testing models, available [here](https://github.com/bpben/model_helpers) as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.ensemble as ske\n",
    "import sklearn.svm as svm\n",
    "import sklearn.linear_model as skl\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, StratifiedKFold, GroupKFold, GroupShuffleSplit\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class Indata():\n",
    "    scoring = None\n",
    "    data = None\n",
    "    train_x, train_y, test_x, test_y = None, None, None, None\n",
    "    is_split = 0\n",
    "    \n",
    "    #init with pandas DF and target column name, specify scoring observations\n",
    "    def __init__(self, data, target, scoring=None):\n",
    "        #If scoring observations, store under scoring attribute\n",
    "        if scoring is not None:\n",
    "            self.data = data[~(scoring)]\n",
    "            self.scoring = data[scoring]\n",
    "        else:\n",
    "            self.data = data\n",
    "        self.target = target\n",
    "    \n",
    "    # Split into train/test\n",
    "    # pct : percent training observations\n",
    "    # datesort : specify date column for sorting values\n",
    "    #   If this is not None, split will be non-random (i.e. split on sorted obs)\n",
    "    def tr_te_split(self, pct, datesort=None, group_col=None):\n",
    "        \"\"\"\n",
    "        Split into train/test\n",
    "        pct : percent training observations\n",
    "        datesort : specify date column for sorting values\n",
    "            If this is not None, split will be non-random (i.e. split on sorted obs)\n",
    "        group_col : group column name for groupkfold split\n",
    "            Will also be passed to tuner\n",
    "        \"\"\"\n",
    "        if group_col:\n",
    "            self.group_col = group_col\n",
    "            grouper = GroupShuffleSplit(n_splits=1, train_size=pct)\n",
    "            g = grouper.split(self.data, groups=self.data[group_col])\n",
    "            # get the actual indexes of the training set\n",
    "            inds, _ = tuple(*g)\n",
    "            # translate that into boolean array\n",
    "            inds = self.data.index[inds]\n",
    "            inds = self.data.index.isin(inds)\n",
    "        elif datesort:\n",
    "            self.data.sort_values(datesort, inplace=True)\n",
    "            self.data.reset_index(drop=True, inplace=True)\n",
    "            inds = np.arange(0.0,len(self.data)) / len(self.data) < pct\n",
    "        else:\n",
    "            inds = np.random.rand(len(self.data)) < pct\n",
    "        self.train_x = self.data[inds]\n",
    "        print 'Train obs:', len(self.train_x)\n",
    "        self.train_y = self.data[self.target][inds]\n",
    "        self.test_x = self.data[~inds]\n",
    "        print 'Test obs:', len(self.test_x)\n",
    "        self.test_y = self.data[self.target][~inds]\n",
    "        self.is_split = 1\n",
    "        \n",
    "class Tuner():\n",
    "    \"\"\"\n",
    "    Initiates with indata class, will tune series of models according to parameters.  \n",
    "    Outputs RandomizedGridCV results and parameterized model in dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    data = None\n",
    "    train_x, train_y = None, None\n",
    "    group_col = None\n",
    "    \n",
    "    def __init__(self, indata, best_models=None, grid_results=None):\n",
    "        if indata.is_split == 0:\n",
    "            raise ValueError('Data is not split, cannot be tested')\n",
    "        # check if grouped by some column\n",
    "        if hasattr(indata,'group_col'):\n",
    "            self.group_col = indata.group_col\n",
    "        self.data = indata.data\n",
    "        self.train_x = indata.train_x\n",
    "        self.train_y = indata.train_y\n",
    "        if best_models is None:\n",
    "            self.best_models = {}\n",
    "        if grid_results is None:\n",
    "            self.grid_results = pd.DataFrame()\n",
    "        \n",
    "            \n",
    "    def make_grid(self, model, cvparams, mparams):\n",
    "        #Makes CV grid\n",
    "        # to implement, no capability for GroupKFold for randomizedsearch\n",
    "        #if self.group_col:\n",
    "            #cv = GroupKFold(cvparams['folds'])\n",
    "        grid = RandomizedSearchCV(\n",
    "                    model(),scoring=cvparams['pmetric'], \n",
    "                    cv = KFold(cvparams['folds'], cvparams['shuffle']),\n",
    "                    refit=False, n_iter=cvparams['iter'],\n",
    "                    param_distributions=mparams, verbose=1)\n",
    "        return(grid)\n",
    "    \n",
    "    def run_grid(self, grid, train_x, train_y):\n",
    "        grid.fit(train_x, train_y)\n",
    "        results = pd.DataFrame(grid.cv_results_)[['mean_test_score','mean_train_score','params']]\n",
    "        best = {}\n",
    "        best['bp'] = grid.best_params_\n",
    "        best[grid.scoring] = grid.best_score_\n",
    "        return(best, results)\n",
    "            \n",
    "    def tune(self, name, m_name, features, cvparams, mparams):\n",
    "        if hasattr(ske, m_name):\n",
    "            model = getattr(ske, m_name)\n",
    "        elif hasattr(skl, m_name):\n",
    "            model = getattr(skl, m_name)\n",
    "        elif hasattr(xgb, m_name):\n",
    "            model = getattr(xgb, m_name)\n",
    "        elif hasattr(svm, m_name):\n",
    "            model = getattr(svm, m_name)\n",
    "        else:\n",
    "            raise ValueError('Model name is invalid.')\n",
    "        grid = self.make_grid(model, cvparams, mparams)\n",
    "        best, results = self.run_grid(grid, self.train_x[features], self.train_y)\n",
    "        results['name'] = name\n",
    "        results['m_name'] = m_name\n",
    "        self.grid_results = self.grid_results.append(results)\n",
    "        best['model'] = model(**best['bp'])\n",
    "        best['features'] = list(features)\n",
    "        self.best_models.update({name: best}) \n",
    "        \n",
    "class Tester():\n",
    "    \"\"\"\n",
    "    Initiates with indata class, receives parameterized sklearn models, prints and stores results\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, rundict=None):\n",
    "        if data.is_split == 0 :\n",
    "            raise ValueError('Data is not split, cannot be tested')\n",
    "        else:\n",
    "            self.data = data\n",
    "            if rundict is None:\n",
    "                self.rundict = {}\n",
    "            \n",
    "    def init_tuned(self, tuned):\n",
    "        \"\"\" pass Tuner object, populatest with names, models, features \"\"\"\n",
    "        if tuned.best_models=={}:\n",
    "            raise ValueError('No tuned models found')\n",
    "        else:\n",
    "            self.rundict.update(tuned.best_models)\n",
    "    \n",
    "    def predsprobs(self, model, test_x):\n",
    "        \"\"\" Produce predicted class and probabilities \"\"\"\n",
    "        # if the model doesn't have predict proba, will be treated as GLM\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            preds = model.predict(test_x)\n",
    "            probs = model.predict_proba(test_x)[:,1]\n",
    "        else:\n",
    "            probs = model.predict(test_x)\n",
    "            preds = (probs>=.5).astype(int)\n",
    "        return(preds, probs)\n",
    "    \n",
    "    def get_metrics(self, preds, probs, test_y):\n",
    "        \"\"\" Produce metrics (f1 score, AUC, brier) \"\"\"\n",
    "        # if test is not binary, just run brier\n",
    "        if len(np.unique(test_y))==2:\n",
    "            f1_s = metrics.f1_score(test_y, preds)\n",
    "            roc = metrics.roc_auc_score(test_y, probs)\n",
    "        else:\n",
    "            f1_s, roc = None, None\n",
    "        brier = metrics.brier_score_loss(test_y, probs)\n",
    "        return(f1_s, roc, brier)\n",
    "    \n",
    "    def make_result(self, model, test_x, test_y):\n",
    "        \"\"\" gets predictions and runs metrics \"\"\"\n",
    "        preds, probs = self.predsprobs(model, test_x)\n",
    "        f1_s, roc, brier = self.get_metrics(preds, probs, test_y)\n",
    "        print \"f1_score: \", f1_s\n",
    "        print \"roc auc: \", roc\n",
    "        print \"brier_score: \", brier\n",
    "        result = {}\n",
    "        result['f1_s'] = f1_s\n",
    "        result['roc'] = roc\n",
    "        result['brier'] = brier\n",
    "        return(result)\n",
    "\n",
    "    \n",
    "    def run_model(self, name, model, features, cal=True, cal_m='sigmoid'):\n",
    "        \"\"\"\n",
    "        Run a specific model (not from Tuner classs)\n",
    "        By default, calibrates predictions and produces metrics for them\n",
    "        Will also store in rundict object\n",
    "        \"\"\"\n",
    "\n",
    "        results = {}\n",
    "        results['features'] = list(features)\n",
    "        results['model'] = model\n",
    "        print \"Fitting {} model with {} features\".format(name, len(features))\n",
    "        if cal:\n",
    "            # Need disjoint calibration/training datasets\n",
    "            # Split 50/50\n",
    "            rnd_ind = np.random.rand(len(self.data.train_x)) < .5\n",
    "            train_x = self.data.train_x[features][rnd_ind]\n",
    "            train_y = self.data.train_y[rnd_ind]\n",
    "            cal_x = self.data.train_x[features][~rnd_ind]\n",
    "            cal_y = self.data.train_y[~rnd_ind]\n",
    "        else:\n",
    "            train_x = self.data.train_x[features]\n",
    "            train_y = self.data.train_y\n",
    "\n",
    "        m_fit = model.fit(train_x, train_y)\n",
    "        result = self.make_result(\n",
    "            m_fit,\n",
    "            self.data.test_x[features],\n",
    "            self.data.test_y)\n",
    "\n",
    "        results['raw'] = result\n",
    "        results['m_fit'] = m_fit\n",
    "        if cal:\n",
    "            print \"calibrated:\"\n",
    "            m_c = CalibratedClassifierCV(model, method = cal_m)\n",
    "            m_fit_c = m_c.fit(cal_x, cal_y)\n",
    "            result_c = self.make_result(m_fit_c, self.data.test_x[features], self.data.test_y)\n",
    "            results['calibrated'] = result_c              \n",
    "            print \"\\n\"\n",
    "        if name in self.rundict:\n",
    "            self.rundict[name].update(results)\n",
    "        else:\n",
    "            self.rundict.update({name:results})\n",
    "    \n",
    "    def run_tuned(self, name, cal=True, cal_m='sigmoid'):\n",
    "        \"\"\" Wrapper for run_model when using Tuner object \"\"\"\n",
    "        self.run_model(name, self.rundict[name]['model'], self.rundict[name]['features'], cal, cal_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "The approach here is to create 3 time-lag features:\n",
    "\n",
    "1. crashes in the past week\n",
    "2. crashes in the past month\n",
    "3. crashes in the past quarter (three months)\n",
    "4. average crashes per week up to target week\n",
    "\n",
    "All features except 4 are calculated to exclude one another.  That is, crashes in the past month does not include the past week's crashes.  Crashes in the past quarter do not include the past month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEG_CHARS = ['AADT', 'SPEEDLIMIT', 'Struct_Cnd', 'Surface_Tp', 'F_F_Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv('../../data/processed/vz_predict_dataset.csv.gz', compression='gzip', dtype={'segment_id':'str'})\n",
    "data.sort_values(['segment_id', 'year', 'week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get segments with non-zero crashes\n",
    "data_nonzero = data.set_index('segment_id').loc[data.groupby('segment_id').crash.sum()>0]\n",
    "data_nonzero.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_crash_data(data, col, target_week, target_year):\n",
    "    \"\"\" formats crash data for train/test \n",
    "    target_week: week to predict (make into binary target)\n",
    "    target_year: year for predicted week\n",
    "    note: data must be available for 4 months prior to target\n",
    "    gets previous week count, previous month count, previous quarter count, avg per week\n",
    "    \"\"\"\n",
    "    assert target_week>16\n",
    "    pre_week = target_week - 1\n",
    "    pre_month = range(pre_week-4, target_week)\n",
    "    pre_quarter = range(pre_month[0]-12, target_week)\n",
    "    \n",
    "    # week interval for each segment\n",
    "    # full range = pre_quarter : target\n",
    "    sliced = data.loc[(slice(None),slice(target_year,target_year), slice(1, target_week)),:]\n",
    "    week_data = sliced[col].unstack(2)\n",
    "    week_data.reset_index(level=1, inplace=True)\n",
    "    \n",
    "    # aggregate\n",
    "    week_data['pre_month'] = week_data[pre_month].sum(axis=1)\n",
    "    week_data['pre_quarter'] = week_data[pre_quarter].sum(axis=1)\n",
    "    week_data['pre_week'] = week_data[pre_week]\n",
    "\n",
    "    # avg as of target week\n",
    "    except_target = data.loc[(slice(None),\n",
    "                       slice(target_year,target_year),\n",
    "                       slice(target_week,None)),:].index\n",
    "    avg_week = data.drop(except_target)\n",
    "    avg_week = avg_week.reset_index().groupby('segment_id')[col].mean()\n",
    "    avg_week.name = 'avg_week'\n",
    "    # join to week data\n",
    "    week_data = week_data.join(avg_week)\n",
    "\n",
    "    # binarize target\n",
    "    week_data['target'] = (week_data[target_week]>0).astype(int)\n",
    "    week_data = week_data.reset_index()\n",
    "\n",
    "    return(week_data[['segment_id','target', 'pre_week',\n",
    "                      'pre_month', 'pre_quarter', 'avg_week']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple add concern, any concern reported 2016\n",
    "concern_observed = data_nonzero[data_nonzero.year==2016].groupby('segment_id').concern.max()\n",
    "concern_observed.name = 'concern_observed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crash_lags = format_crash_data(data_nonzero.set_index(['segment_id','year','week']), 'crash', 19, 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_segs = data_nonzero.groupby('segment_id')[SEG_CHARS].max()  # grab the highest values from each column for a segment, not used in model?\n",
    "data_segs.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in atrs\n",
    "atrs = pd.read_csv('../../data/processed/atrs_predicted.csv', dtype={'id':'str'})\n",
    "# for some reason pandas reads the id as float before str conversions\n",
    "atrs['id'] = atrs.id.apply(lambda x: x.split('.')[0])\n",
    "data_segs = data_segs.merge(atrs[['id','speed_coalesced', 'volume_coalesced']], \n",
    "                            left_on='segment_id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in tmcs - conflicts\n",
    "# it either has some or doesn't\n",
    "# I think just filling na = 0 should work for now\n",
    "tmcs = pd.read_json('../../data/processed/tmc_summary.json',\n",
    "                   dtype={'near_id':str})[['near_id','Conflict']]\n",
    "data_segs = data_segs.merge(tmcs, left_on='segment_id', right_on='near_id', how='left')\n",
    "data_segs.Conflict.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_model = crash_lags.merge(data_segs, left_on='segment_id', right_on='segment_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add concerns\n",
    "data_model = data_model.merge(concern_observed.reset_index(), on='segment_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add in adjacency info\n",
    "adj_info = pd.read_csv('../../data/processed/adjacency_info.csv', usecols=['segment_id', 'orig_id'],\n",
    "                       dtype={'segment_id':'str', 'orig_id':'str'})\n",
    "\n",
    "# link adjacent segments for segments with crashes\n",
    "adj_info = adj_info[adj_info.segment_id.isin(data_model.segment_id)]\n",
    "adj_mat = adj_info.merge(adj_info, on='orig_id')\n",
    "adj_mat = adj_mat[['segment_id_x', 'segment_id_y']]\n",
    "adj_mat.drop_duplicates(inplace=True)\n",
    "# including segments with only self-adjacent\n",
    "# for this, need to ensure they don't join to their own data\n",
    "adj_mat.loc[adj_mat.segment_id_x==adj_mat.segment_id_y, 'segment_id_y'] = np.NaN\n",
    "\n",
    "def get_adj_crash_lags(target_week, target_year):\n",
    "    \"\"\"calculate total number of crashes that occurred \n",
    "    in adjacent segments for target week and lags as defined in format_crash_data\n",
    "    \"\"\" \n",
    "    lag_data = format_crash_data(data_nonzero.set_index(['segment_id','year','week']), 'crash', target_week, target_year)\n",
    "    merge_lags = adj_mat.merge(lag_data, left_on='segment_id_y', right_on='segment_id', how='left')\n",
    "    adj_lags = merge_lags.groupby(['segment_id_x'])['pre_week', 'pre_month', 'pre_quarter'].sum()\n",
    "    return adj_lags\n",
    "\n",
    "adj_lags = get_adj_crash_lags(19, 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill those with only self-adj zero\n",
    "adj_lags.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_model = data_model.merge(adj_lags, how='left', left_on='segment_id', right_index=True, suffixes=('', '_adj'))\n",
    "data_model.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize for LR\n",
    "#from sklearn.preprocessing import scale\n",
    "#data_scaled = pd.DataFrame(scale(data_model['AADT', 'SPEEDLIMIT']), \n",
    "#                          columns=[f+'_scaled' for f in features])\n",
    "#data_model = pd.concat([data_model, data_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying a different feature set\n",
    "dummy_att = ['SPEEDLIMIT', 'Struct_Cnd', 'Surface_Tp', 'F_F_Class']\n",
    "for d in dummy_att:\n",
    "    t = pd.get_dummies(data_model[d])\n",
    "    t.columns = [d+str(c) for c in t.columns]\n",
    "    data_model = pd.concat([data_model, t], axis=1)\n",
    "# aadt - log-transform\n",
    "data_model['log_aadt'] = np.log(data_model.AADT+1)\n",
    "# add segment type\n",
    "data_model['intersection'] = data_model.segment_id.map(lambda x: x[:2]!='00').astype(int)\n",
    "# features\n",
    "features = data_model.filter(regex='[0-9]').columns.tolist() + ['log_aadt', 'intersection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Features\n",
    "#features = [u'pre_week', u'pre_month', u'pre_quarter', 'avg_week', u'AADT', u'SPEEDLIMIT',\n",
    "#            u'Struct_Cnd', u'Surface_Tp', u'F_F_Class', u'pre_week_adj', \n",
    "#            u'pre_month_adj', u'pre_quarter_adj']\n",
    "features += [u'pre_week', u'pre_month', u'pre_quarter', 'avg_week', 'concern_observed']\n",
    "#features += ['speed_coalesced', 'volume_coalesced']\n",
    "#features += ['Conflict']\n",
    "lm_features = list(set(features) - set(['SPEEDLIMIT1', 'Struct_Cnd0', 'F_F_Class0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [u'pre_week', u'pre_month', u'pre_quarter', 'avg_week', 'concern_observed']\n",
    "lm_features = [u'pre_week', u'pre_month', u'pre_quarter', 'avg_week', 'concern_observed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model tuning\n",
    "This uses the model helpers above.  They're based on sklearn and implement a randomized grid search with K-fold crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train obs: 2283\n",
      "Test obs: 1026\n"
     ]
    }
   ],
   "source": [
    "#Initialize data\n",
    "df = Indata(data_model, 'target')\n",
    "#Create train/test split\n",
    "df.tr_te_split(.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters for model\n",
    "# class weight\n",
    "a = data_model['target'].value_counts(normalize=True)\n",
    "w = 1/a[1]\n",
    "#Model parameters\n",
    "params = dict()\n",
    "\n",
    "#cv parameters\n",
    "cvp = dict()\n",
    "cvp['pmetric'] = 'roc_auc'\n",
    "cvp['iter'] = 5 #number of iterations\n",
    "cvp['folds'] = 5 #folds for cv (default)\n",
    "cvp['shuffle'] = True\n",
    "\n",
    "#LR parameters\n",
    "mp = dict()\n",
    "mp['LogisticRegression'] = dict()\n",
    "mp['LogisticRegression']['penalty'] = ['l1','l2']\n",
    "mp['LogisticRegression']['C'] = ss.beta(a=5,b=2) #beta distribution for selecting reg strength\n",
    "mp['LogisticRegression']['class_weight'] = ['balanced']\n",
    "\n",
    "#RF model parameters\n",
    "mp['RandomForestClassifier'] = dict()\n",
    "mp['RandomForestClassifier']['n_estimators'] = [2**8] #number of trees in the forest\n",
    "mp['RandomForestClassifier']['max_features'] = ss.beta(a=5,b=1) #number of features at split\n",
    "mp['RandomForestClassifier']['max_leaf_nodes'] = ss.nbinom(n=2,p=0.001,loc=100) #max number of leaves to create\n",
    "#mp['RandomForestClassifier']['class_weight'] = ['balanced']\n",
    "mp['RandomForestClassifier']['class_weight'] = [{0:1,1:w}]\n",
    "\n",
    "\n",
    "#xgBoost model parameters\n",
    "mp['XGBClassifier'] = dict()\n",
    "mp['XGBClassifier']['max_depth'] = range(3, 7)\n",
    "mp['XGBClassifier']['min_child_weight'] = range(1, 5)\n",
    "mp['XGBClassifier']['learning_rate'] = ss.beta(a=2,b=15)\n",
    "mp['XGBClassifier']['scale_pos_weight'] = [w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize tuner\n",
    "tune = Tuner(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "#Base XG model\n",
    "tune.tune('XG_base', 'XGBClassifier', features, cvp, mp['XGBClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   28.9s finished\n"
     ]
    }
   ],
   "source": [
    "#Base RF model\n",
    "tune.tune('RF_base', 'RandomForestClassifier', features, cvp, mp['RandomForestClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "#Base LR model\n",
    "tune.tune('LR_base', 'LogisticRegression', lm_features, cvp, mp['LogisticRegression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>params</th>\n",
       "      <th>name</th>\n",
       "      <th>m_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.570937</td>\n",
       "      <td>0.925798</td>\n",
       "      <td>{u'scale_pos_weight': 62.4339622642, u'learnin...</td>\n",
       "      <td>XG_base</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.691149</td>\n",
       "      <td>0.896836</td>\n",
       "      <td>{u'scale_pos_weight': 62.4339622642, u'learnin...</td>\n",
       "      <td>XG_base</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.689410</td>\n",
       "      <td>0.895132</td>\n",
       "      <td>{u'scale_pos_weight': 62.4339622642, u'learnin...</td>\n",
       "      <td>XG_base</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.598525</td>\n",
       "      <td>0.912797</td>\n",
       "      <td>{u'scale_pos_weight': 62.4339622642, u'learnin...</td>\n",
       "      <td>XG_base</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.577181</td>\n",
       "      <td>0.924197</td>\n",
       "      <td>{u'scale_pos_weight': 62.4339622642, u'learnin...</td>\n",
       "      <td>XG_base</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.520084</td>\n",
       "      <td>0.913345</td>\n",
       "      <td>{u'max_features': 0.926177384668, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.519600</td>\n",
       "      <td>0.913295</td>\n",
       "      <td>{u'max_features': 0.938848893913, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.525286</td>\n",
       "      <td>0.913904</td>\n",
       "      <td>{u'max_features': 0.650732659335, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.525012</td>\n",
       "      <td>0.913663</td>\n",
       "      <td>{u'max_features': 0.69138125494, u'max_leaf_no...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.526392</td>\n",
       "      <td>0.913347</td>\n",
       "      <td>{u'max_features': 0.556544822452, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.596121</td>\n",
       "      <td>0.650392</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.539092293986, u'cl...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.613317</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>{u'penalty': u'l1', u'C': 0.620294341653, u'cl...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.617464</td>\n",
       "      <td>0.666792</td>\n",
       "      <td>{u'penalty': u'l1', u'C': 0.938222052108, u'cl...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.612989</td>\n",
       "      <td>0.662515</td>\n",
       "      <td>{u'penalty': u'l1', u'C': 0.600900553963, u'cl...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.615895</td>\n",
       "      <td>0.665359</td>\n",
       "      <td>{u'penalty': u'l1', u'C': 0.757488167384, u'cl...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  mean_train_score  \\\n",
       "0         0.570937          0.925798   \n",
       "1         0.691149          0.896836   \n",
       "2         0.689410          0.895132   \n",
       "3         0.598525          0.912797   \n",
       "4         0.577181          0.924197   \n",
       "0         0.520084          0.913345   \n",
       "1         0.519600          0.913295   \n",
       "2         0.525286          0.913904   \n",
       "3         0.525012          0.913663   \n",
       "4         0.526392          0.913347   \n",
       "0         0.596121          0.650392   \n",
       "1         0.613317          0.662745   \n",
       "2         0.617464          0.666792   \n",
       "3         0.612989          0.662515   \n",
       "4         0.615895          0.665359   \n",
       "\n",
       "                                              params     name  \\\n",
       "0  {u'scale_pos_weight': 62.4339622642, u'learnin...  XG_base   \n",
       "1  {u'scale_pos_weight': 62.4339622642, u'learnin...  XG_base   \n",
       "2  {u'scale_pos_weight': 62.4339622642, u'learnin...  XG_base   \n",
       "3  {u'scale_pos_weight': 62.4339622642, u'learnin...  XG_base   \n",
       "4  {u'scale_pos_weight': 62.4339622642, u'learnin...  XG_base   \n",
       "0  {u'max_features': 0.926177384668, u'max_leaf_n...  RF_base   \n",
       "1  {u'max_features': 0.938848893913, u'max_leaf_n...  RF_base   \n",
       "2  {u'max_features': 0.650732659335, u'max_leaf_n...  RF_base   \n",
       "3  {u'max_features': 0.69138125494, u'max_leaf_no...  RF_base   \n",
       "4  {u'max_features': 0.556544822452, u'max_leaf_n...  RF_base   \n",
       "0  {u'penalty': u'l2', u'C': 0.539092293986, u'cl...  LR_base   \n",
       "1  {u'penalty': u'l1', u'C': 0.620294341653, u'cl...  LR_base   \n",
       "2  {u'penalty': u'l1', u'C': 0.938222052108, u'cl...  LR_base   \n",
       "3  {u'penalty': u'l1', u'C': 0.600900553963, u'cl...  LR_base   \n",
       "4  {u'penalty': u'l1', u'C': 0.757488167384, u'cl...  LR_base   \n",
       "\n",
       "                   m_name  \n",
       "0           XGBClassifier  \n",
       "1           XGBClassifier  \n",
       "2           XGBClassifier  \n",
       "3           XGBClassifier  \n",
       "4           XGBClassifier  \n",
       "0  RandomForestClassifier  \n",
       "1  RandomForestClassifier  \n",
       "2  RandomForestClassifier  \n",
       "3  RandomForestClassifier  \n",
       "4  RandomForestClassifier  \n",
       "0      LogisticRegression  \n",
       "1      LogisticRegression  \n",
       "2      LogisticRegression  \n",
       "3      LogisticRegression  \n",
       "4      LogisticRegression  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display results\n",
    "tune.grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RF_base model with 5 features\n",
      "f1_score:  0.0808080808081\n",
      "roc auc:  0.50969756739\n",
      "brier_score:  0.082643868542\n",
      "Fitting LR_base model with 5 features\n",
      "f1_score:  0.04329004329\n",
      "roc auc:  0.507149901381\n",
      "brier_score:  0.215432772864\n",
      "Fitting XG_base model with 5 features\n",
      "f1_score:  0.0590717299578\n",
      "roc auc:  0.73553583169\n",
      "brier_score:  0.148797567842\n"
     ]
    }
   ],
   "source": [
    "# Run test\n",
    "test = Tester(df)\n",
    "test.init_tuned(tune)\n",
    "test.run_tuned('RF_base', cal=False)\n",
    "test.run_tuned('LR_base', cal=False)\n",
    "test.run_tuned('XG_base', cal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RF_base model with 5 features\n",
      "f1_score:  0.0816326530612\n",
      "roc auc:  0.47702991453\n",
      "brier_score:  0.0824300972342\n",
      "Fitting LR_base model with 5 features\n",
      "f1_score:  0.04329004329\n",
      "roc auc:  0.507149901381\n",
      "brier_score:  0.215432530339\n",
      "Fitting XG_base model with 5 features\n",
      "f1_score:  0.0590717299578\n",
      "roc auc:  0.73553583169\n",
      "brier_score:  0.148797567842\n"
     ]
    }
   ],
   "source": [
    "# Run test\n",
    "test = Tester(df)\n",
    "test.init_tuned(tune)\n",
    "test.run_tuned('RF_base', cal=False)\n",
    "test.run_tuned('LR_base', cal=False)\n",
    "test.run_tuned('XG_base', cal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73553583168967784"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = test.rundict['XG_base']['m_fit'].predict_proba(test.data.test_x[features])[::,1]\n",
    "metrics.roc_auc_score(test.data.test_y,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('avg_week', 0.52067667), ('concern_observed', 0.2631579), (u'pre_quarter', 0.14661655), (u'pre_month', 0.037593983), (u'pre_week', 0.031954888)]\n"
     ]
    }
   ],
   "source": [
    "# Check feature importance\n",
    "f_importance = test.rundict['XG_base']['m_fit'].feature_importances_\n",
    "fi = list(zip(features, f_importance))\n",
    "print sorted(fi, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7282994514359471"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying some other models\n",
    "minus_adj = list(set(lm_features) - set([x for x in lm_features if x.find('volume')!=-1]))\n",
    "xg = xgb.XGBClassifier(**test.rundict['XG_base']['bp'])\n",
    "xg.fit(test.data.train_x[minus_adj], test.data.train_y)\n",
    "preds = xg.predict_proba(\n",
    "    test.data.test_x[minus_adj])[::,1]\n",
    "roc_auc_score(test.data.test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63632752151842864"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying some other models\n",
    "minus_adj = list(set(lm_features) - set([x for x in lm_features if x.find('adj')!=-1]))\n",
    "lr = skl.LogisticRegression(**test.rundict['LR_base']['bp'])\n",
    "lr.fit(test.data.train_x[minus_adj], test.data.train_y)\n",
    "preds = lr.predict_proba(\n",
    "    test.data.test_x[minus_adj])[::,1]\n",
    "roc_auc_score(test.data.test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n",
      "/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/ipykernel_launcher.py:4: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.56241447804016775"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = skl.LogisticRegression(**test.rundict['LR_base']['bp'])\n",
    "lr.fit(test.data.train_x['avg_week'].reshape(-1,1), test.data.train_y)\n",
    "preds = lr.predict_proba(\n",
    "    test.data.test_x['avg_week'].reshape(-1,1))[::,1]\n",
    "roc_auc_score(test.data.test_y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift chart by \"risk bin\"\n",
    "The classifier problem is difficult because the classes are unbalanced (.05% have crashes at target week).  More useful are the probabilities being produced by the model, which give some idea of risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lift_chart(x_col, y_col, data, ax=None):\n",
    "\n",
    "    p = sns.barplot(x=x_col, y=y_col, data=data, \n",
    "                    palette='Reds', ax = None, ci=None)\n",
    "    vals = p.get_yticks()\n",
    "    p.set_yticklabels(['{:3.0f}%'.format(i*100) for i in vals])\n",
    "    xvals = [x.get_text().split(',')[-1].strip(']') for x in p.get_xticklabels()]\n",
    "    xvals = ['{:3.0f}%'.format(float(x)*100) for x in xvals]\n",
    "    p.set_xticklabels(xvals)\n",
    "    p.set_facecolor('white')\n",
    "    p.set_xlabel('')\n",
    "    p.set_ylabel('')\n",
    "    p.set_title('Predicted probability vs actual percent')\n",
    "    return(p)\n",
    "    \n",
    "def density(data, score, ax=None):\n",
    "    p = sns.kdeplot(risk_df['risk_score'], ax=ax)\n",
    "    p.set_facecolor('white')\n",
    "    p.legend('')\n",
    "    p.set_xlabel('Predicted probability of crash')\n",
    "    p.set_title('KDE plot predictions')\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.qcut(risk_df['risk_score'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1026.000000\n",
      "mean        0.449907\n",
      "std         0.114593\n",
      "min         0.320527\n",
      "25%         0.367971\n",
      "50%         0.390528\n",
      "75%         0.492496\n",
      "max         0.999997\n",
      "Name: risk_score, dtype: float64\n",
      "categories\n",
      "[0.321, 0.368]    404\n",
      "(0.368, 0.391]    124\n",
      "(0.391, 0.492]    279\n",
      "(0.492, 1]        219\n",
      "Name: crash, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "risk_scores = test.rundict['LR_base']['m_fit'].predict_proba(test.data.test_x[features])[:,1]\n",
    "risk_df = pd.DataFrame({'risk_score':risk_scores, 'crash':test.data.test_y})\n",
    "print risk_df.risk_score.describe()\n",
    "risk_df['categories'] = pd.qcut(risk_df['risk_score'], 4)\n",
    "risk_mean = risk_df.groupby('categories')['crash'].count()\n",
    "print risk_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11daa7790>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAFlCAYAAACnT5IMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113dd8e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "lift_chart('categories', 'crash', risk_df, \n",
    "           ax=axes[1])\n",
    "density(risk_df, 'risk_score', ax=axes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output predictions\n",
    "# predict on all segments\n",
    "data_model['risk_score'] = test.rundict['RF_base']['m_fit'].predict_proba(data_model[features])[:,1]\n",
    "data_model.to_csv('seg_with_risk_score_adj.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check sensitivity to week\n",
    "I predicted an arbitrary week as target here, but I'd like to see whether things change significantly if I change that week.  A good metric to measure that is brier score loss.  It'll be low throughout as the classifier doesn't perform great, but it shouldn't vary a huge amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model_for_week(weeks=[20, 30, 40, 50], output=False):\n",
    "    for w in [20, 30, 40, 50]:\n",
    "        print \"week \", w\n",
    "        crash_lags = format_crash_data(data_nonzero.set_index(['segment_id','year','week']), 'crash', w, 2016)\n",
    "        data = crash_lags.merge(data_segs, left_on='segment_id', right_on='segment_id')\n",
    "        adj_lags = get_adj_crash_lags(w, 2016)\n",
    "        data = data.merge(adj_lags, left_on='segment_id', right_index=True, suffixes=('', '_adj'))\n",
    "        data.fillna(0, inplace=True)\n",
    "        df = Indata(data, 'target')\n",
    "        # create train/test split\n",
    "        df.tr_te_split(.7)\n",
    "        test = Tester(df)\n",
    "        test.init_tuned(tune)\n",
    "        test.run_tuned('LR_base', cal=False)\n",
    "        print '\\n'\n",
    "    if output==True:\n",
    "        return(test.rundict['LR_base']['m_fit'].pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week  20\n",
      "Train obs: 2367\n",
      "Test obs: 1011\n",
      "Fitting LR_base model with 12 features\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"[u'pre_week_scaled' u'pre_month_scaled' u'pre_quarter_scaled'\\n 'avg_week_scaled' u'AADT_scaled' u'SPEEDLIMIT_scaled' u'Struct_Cnd_scaled'\\n u'Surface_Tp_scaled' u'F_F_Class_scaled' u'pre_week_adj_scaled'\\n u'pre_month_adj_scaled' u'pre_quarter_adj_scaled'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-78ff6e31933f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_model_for_week\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-100-9c5526570564>\u001b[0m in \u001b[0;36mrun_model_for_week\u001b[0;34m(weeks, output)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_tuned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_tuned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LR_base'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e9484aaf2483>\u001b[0m in \u001b[0;36mrun_tuned\u001b[0;34m(self, name, cal, cal_m)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m#Run from tuned set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_tuned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal_m\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrundict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrundict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;31m#Output rundict to csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e9484aaf2483>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(self, name, model, features, cal, cal_m)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mcal_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mrnd_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2095\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2097\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2098\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1228\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[u'pre_week_scaled' u'pre_month_scaled' u'pre_quarter_scaled'\\n 'avg_week_scaled' u'AADT_scaled' u'SPEEDLIMIT_scaled' u'Struct_Cnd_scaled'\\n u'Surface_Tp_scaled' u'F_F_Class_scaled' u'pre_week_adj_scaled'\\n u'pre_month_adj_scaled' u'pre_quarter_adj_scaled'] not in index\""
     ]
    }
   ],
   "source": [
    "run_model_for_week()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# week predictions output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
